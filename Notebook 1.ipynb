{"cells":[{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"tags":[],"cell_id":"1d752014d69447eab6d80216ebf3c1f6","source_hash":"7958d4a9","execution_start":1663553185062,"execution_millis":9828,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":1},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Collecting es-dep-news-trf@ https://github.com/explosion/spacy-models/releases/download/es_dep_news_trf-3.4.0/es_dep_news_trf-3.4.0-py3-none-any.whl\n  Downloading https://github.com/explosion/spacy-models/releases/download/es_dep_news_trf-3.4.0/es_dep_news_trf-3.4.0-py3-none-any.whl (410.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.2/410.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy[lookups,transformers] in /shared-libs/python3.9/py/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.4.1)\nRequirement already satisfied: thinc<8.2.0,>=8.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (8.1.1)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.4.4)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.6.2)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.23.3)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.10.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.28.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.9.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.0.10)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.3.0)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (4.64.1)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.0.7)\nRequirement already satisfied: jinja2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.11.3)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (58.1.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.0.8)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.0.3)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.4.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.0.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.0.8)\nRequirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in /root/venv/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.0.3)\nRequirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in /root/venv/lib/python3.9/site-packages (from spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.1.8)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pathy>=0.3.5->spacy[lookups,transformers]->-r requirements.txt (line 1)) (5.2.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy[lookups,transformers]->-r requirements.txt (line 1)) (4.3.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (2022.6.15.1)\nRequirement already satisfied: transformers<4.22.0,>=3.4.0 in /root/venv/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (4.21.3)\nRequirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /root/venv/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.8.5)\nRequirement already satisfied: torch>=1.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (1.12.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.0.1)\nRequirement already satisfied: blis<0.10.0,>=0.7.8 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.9.1)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy[lookups,transformers]->-r requirements.txt (line 1)) (8.1.3)\nRequirement already satisfied: MarkupSafe>=0.23 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jinja2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (2.0.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /root/venv/lib/python3.9/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.9.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /root/venv/lib/python3.9/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (2022.9.11)\nRequirement already satisfied: pyyaml>=5.1 in /root/venv/lib/python3.9/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: filelock in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[lookups,transformers]->-r requirements.txt (line 1)) (3.8.0)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport spacy\nimport os\nimport json\nimport codecs\nimport pickle\nimport random\nimport csv","metadata":{"tags":[],"cell_id":"30d313978ea44974a2126476089c4908","source_hash":"69775091","execution_start":1663553194892,"execution_millis":9115,"deepnote_app_coordinates":{"h":9,"w":12,"x":0,"y":7},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-09-19 02:06:34.905731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-19 02:06:35.045846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-09-19 02:06:35.045887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-09-19 02:06:35.082138: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-09-19 02:06:37.362120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-09-19 02:06:37.362204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-09-19 02:06:37.362214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2022-09-19 02:06:43.089372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-09-19 02:06:43.089404: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2022-09-19 02:06:43.089421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-829e846e-3785-491b-bcb1-f78f25dd8f99): /proc/driver/nvidia/version does not exist\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"construyendo el dataset","metadata":{"tags":[],"cell_id":"0153dd3c7c544b0695edb1a2bb912682","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":2,"w":8,"x":0,"y":17},"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"nlp = spacy.load('es_dep_news_trf')\n\n\ndata = json.loads(codecs.open(\n    'categorias.json', 'r', encoding='utf-8').read())\nprint(data)\n","metadata":{"tags":[],"cell_id":"035e1704112b4de5853c2e1140ff1708","source_hash":"a6b69105","execution_start":1663553204012,"execution_millis":4013,"deepnote_app_coordinates":{"h":9,"w":12,"x":0,"y":20},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"{'categorias': [{'categoria': 'saludos', 'sentencias': ['hola', 'hey', 'buenos dias', 'hola, que tal'], 'respuestas': ['hola', 'buenos días', 'hola, en que puedo ayudarte?']}, {'categoria': 'despedida', 'sentencias': ['hasta pronto', 'tenga un buen dia', 'nos vemos', 'hasta luego', 'adios', 'fue un gusto hablar contigo'], 'respuestas': ['hasta luego', 'tenga un buen dia usted', 'nos vemos, me encanto conversar contigo']}, {'categoria': 'nombre', 'sentencias': ['cual es tu nombre', 'como te llamas', 'quien eres', 'como te conocen'], 'respuestas': ['mi nombre es Neural', 'me llamo Neural', 'soy Neural una ia amistosa', 'todos me conocen como Neural tu ia amigable']}, {'categoria': 'edad', 'sentencias': ['cuantos años tienes', 'cual es tu edad', 'que edad tienes', 'cuan viejo eres', 'hace cuanto estas creado', 'desde cuando te crearon', 'cuando naciste'], 'respuestas': ['tengo 6 meses de vida', '6 meses es lo que tengo de creada', 'Angel me creo hace 6 meses']}, {'categoria': 'funcionamiento', 'sentencias': ['a que te dedicas', 'que haces', 'como trabajas', 'como funcionas'], 'respuestas': ['soy una ia amigable para chatear con personas', 'soy una ia principiante que puedo contestar pocas cosas por el momento']}]}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"palabras = set()\ncategorias = []\ncategorias_lemmas = []\nignorar = [\"?\", \"!\", \",\", \".\", \":\"]\nfor categoria in data[\"categorias\"]:\n    lematizacion = set()\n    for sentencia in categoria[\"sentencias\"]:\n        print(\"Procesando->\", sentencia)\n        tokens = nlp(sentencia)\n        lemmas = [tok.lemma_.lower()\n                  for tok in tokens if tok.text not in ignorar]\n        lematizacion = lematizacion.union(set(lemmas))\n        categorias_lemmas.append([lematizacion, categoria[\"categoria\"]])\n    palabras = palabras.union(lematizacion)\n    categorias.append(categoria[\"categoria\"])\nprint(palabras)\nprint(categorias_lemmas)","metadata":{"tags":[],"cell_id":"bd7f7f1d83754f6c8939d4c826f9ec3d","source_hash":"c7673f98","execution_start":1663553207721,"execution_millis":4376,"deepnote_app_coordinates":{"h":38,"w":12,"x":0,"y":30},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Procesando-> hola\nProcesando-> hey\n/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\nProcesando-> buenos dias\nProcesando-> hola, que tal\nProcesando-> hasta pronto\nProcesando-> tenga un buen dia\nProcesando-> nos vemos\nProcesando-> hasta luego\nProcesando-> adios\nProcesando-> fue un gusto hablar contigo\nProcesando-> cual es tu nombre\nProcesando-> como te llamas\nProcesando-> quien eres\nProcesando-> como te conocen\nProcesando-> cuantos años tienes\nProcesando-> cual es tu edad\nProcesando-> que edad tienes\nProcesando-> cuan viejo eres\nProcesando-> hace cuanto estas creado\nProcesando-> desde cuando te crearon\nProcesando-> cuando naciste\nProcesando-> a que te dedicas\nProcesando-> que haces\nProcesando-> como trabajas\nProcesando-> como funcionas\n{'tu', 'gusto', 'tal', 'cuan', 'dedicar', 'crear', 'hacer', 'dia', 'uno', 'como', 'a', 'hasta', 'ver', 'tú', 'ser', 'creado', 'tenga', 'tener', 'edad', 'pronto', 'quien', 'cuanto', 'funcionar', 'llamar', 'conocer', 'hey', 'nacer', 'hablar', 'nombre', 'hola', 'viejo', 'año', 'estar', 'yo', 'luego', 'desde', 'cual', 'buen', 'cuando', 'adios', 'trabajar', 'que'}\n[[{'hola'}, 'saludos'], [{'hey', 'hola'}, 'saludos'], [{'hey', 'dia', 'buen', 'hola'}, 'saludos'], [{'hey', 'que', 'dia', 'hola', 'buen', 'tal'}, 'saludos'], [{'hasta', 'pronto'}, 'despedida'], [{'tenga', 'dia', 'buen', 'uno', 'hasta', 'pronto'}, 'despedida'], [{'yo', 'tenga', 'dia', 'buen', 'uno', 'hasta', 'pronto', 'ver'}, 'despedida'], [{'dia', 'uno', 'hasta', 'ver', 'yo', 'tenga', 'luego', 'buen', 'pronto'}, 'despedida'], [{'dia', 'uno', 'hasta', 'ver', 'yo', 'tenga', 'luego', 'buen', 'pronto', 'adios'}, 'despedida'], [{'dia', 'uno', 'hasta', 'ver', 'gusto', 'tú', 'ser', 'yo', 'tenga', 'luego', 'hablar', 'buen', 'pronto', 'adios'}, 'despedida'], [{'cual', 'nombre', 'tu', 'ser'}, 'nombre'], [{'ser', 'tu', 'como', 'cual', 'llamar', 'nombre', 'tú'}, 'nombre'], [{'tu', 'como', 'llamar', 'tú', 'ser', 'cual', 'nombre', 'quien'}, 'nombre'], [{'tu', 'como', 'llamar', 'tú', 'conocer', 'ser', 'cual', 'nombre', 'quien'}, 'nombre'], [{'tener', 'cuanto', 'año'}, 'edad'], [{'ser', 'tener', 'año', 'tu', 'edad', 'cual', 'cuanto'}, 'edad'], [{'tu', 'año', 'ser', 'tener', 'edad', 'cual', 'cuanto', 'que'}, 'edad'], [{'tu', 'viejo', 'año', 'ser', 'cuan', 'tener', 'edad', 'cual', 'cuanto', 'que'}, 'edad'], [{'tu', 'viejo', 'año', 'hacer', 'estar', 'ser', 'cuan', 'creado', 'tener', 'edad', 'cual', 'cuanto', 'que'}, 'edad'], [{'tu', 'viejo', 'año', 'hacer', 'tú', 'estar', 'ser', 'cuan', 'creado', 'tener', 'crear', 'desde', 'edad', 'cual', 'cuanto', 'cuando', 'que'}, 'edad'], [{'que', 'tu', 'cuan', 'nacer', 'cuando', 'hacer', 'viejo', 'año', 'tú', 'estar', 'ser', 'creado', 'tener', 'desde', 'edad', 'cual', 'crear', 'cuanto'}, 'edad'], [{'dedicar', 'a', 'tú', 'que'}, 'funcionamiento'], [{'que', 'a', 'hacer', 'tú', 'dedicar'}, 'funcionamiento'], [{'que', 'a', 'como', 'hacer', 'tú', 'trabajar', 'dedicar'}, 'funcionamiento'], [{'funcionar', 'a', 'como', 'hacer', 'tú', 'dedicar', 'trabajar', 'que'}, 'funcionamiento']]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"palabras = sorted(palabras)\ncategorias = sorted(categorias)\npickle.dump(palabras, open('palabras.pkl', 'wb'))\npickle.dump(categorias, open('categorias.pkl', 'wb'))\nprint(palabras)\nprint(categorias)","metadata":{"tags":[],"cell_id":"03f421d7d698476588611bef52bf3514","source_hash":"ff6e837d","execution_start":1663553212096,"execution_millis":13,"deepnote_app_coordinates":{"h":9,"w":12,"x":0,"y":69},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"['a', 'adios', 'año', 'buen', 'como', 'conocer', 'creado', 'crear', 'cual', 'cuan', 'cuando', 'cuanto', 'dedicar', 'desde', 'dia', 'edad', 'estar', 'funcionar', 'gusto', 'hablar', 'hacer', 'hasta', 'hey', 'hola', 'llamar', 'luego', 'nacer', 'nombre', 'pronto', 'que', 'quien', 'ser', 'tal', 'tener', 'tenga', 'trabajar', 'tu', 'tú', 'uno', 'ver', 'viejo', 'yo']\n['despedida', 'edad', 'funcionamiento', 'nombre', 'saludos']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"training = []\nfor arr in categorias_lemmas:\n    lemmas = arr[0]\n    categoria = arr[1]\n    salida = [0] * len(categorias)\n    salida[categorias.index(categoria)] = 1\n    index_categoria = categorias.index(categoria)\n    row = []\n    for word in palabras:\n        if word in lemmas:\n            row.append(1)\n        else:\n            row.append(0)\n    training.append([row, salida])\nrandom.shuffle(training)\ntraining = np.array(training, dtype=object)\ntrain_x = list(training[:,0])\ntrain_y = list(training[:,1])\nprint(train_x)\nprint(train_y)","metadata":{"tags":[],"cell_id":"a1d328d84e194b8e9e4292bf350b47b6","source_hash":"1dff74f2","execution_start":1663553212113,"execution_millis":7,"deepnote_app_coordinates":{"h":19,"w":12,"x":0,"y":79},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]\n[[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0]]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(len(palabras))\nprint(len(categorias))\n","metadata":{"tags":[],"cell_id":"aae8677ac2714d62b3d431cc5ada9d61","source_hash":"a1970f22","execution_start":1663553212179,"execution_millis":8,"deepnote_app_coordinates":{"h":7,"w":12,"x":0,"y":99},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"42\n5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.Input(shape=(len(palabras),)))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(.5))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(.5))\nmodel.add(tf.keras.layers.Dense(len(categorias), activation='softmax'))\nopt = tf.keras.optimizers.SGD(learning_rate=0.04, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt, metrics=['accuracy'])\nhist = model.fit(np.array(train_x),np.array(train_y), batch_size=4000, epochs=200, verbose=1)\nmodel.save('chatbot_model.h5', hist)\nprint(\"Done\")","metadata":{"tags":[],"cell_id":"2f48d820716b46aa8166cc646ad01a2d","source_hash":"163347c7","execution_start":1663553212223,"execution_millis":2810,"deepnote_app_coordinates":{"h":36,"w":12,"x":0,"y":107},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 1/200\n2022-09-19 02:06:52.186842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n1/1 [==============================] - 0s 461ms/step - loss: 1.7001 - accuracy: 0.0800\nEpoch 2/200\n1/1 [==============================] - 0s 4ms/step - loss: 1.6267 - accuracy: 0.1600\nEpoch 3/200\n1/1 [==============================] - 0s 3ms/step - loss: 1.5105 - accuracy: 0.2800\nEpoch 4/200\n1/1 [==============================] - 0s 3ms/step - loss: 1.5227 - accuracy: 0.4000\nEpoch 5/200\n1/1 [==============================] - 0s 3ms/step - loss: 1.3167 - accuracy: 0.6000\nEpoch 6/200\n1/1 [==============================] - 0s 3ms/step - loss: 1.2930 - accuracy: 0.4800\nEpoch 7/200\n1/1 [==============================] - 0s 42ms/step - loss: 1.1128 - accuracy: 0.7200\nEpoch 8/200\n1/1 [==============================] - 0s 4ms/step - loss: 1.0715 - accuracy: 0.6000\nEpoch 9/200\n1/1 [==============================] - 0s 4ms/step - loss: 1.0880 - accuracy: 0.5600\nEpoch 10/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.9423 - accuracy: 0.7600\nEpoch 11/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.7200\nEpoch 12/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.8000\nEpoch 13/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.8400\nEpoch 14/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.8000\nEpoch 15/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8400\nEpoch 16/200\n1/1 [==============================] - 0s 52ms/step - loss: 0.5344 - accuracy: 0.8800\nEpoch 17/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.9600\nEpoch 18/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.9600\nEpoch 19/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 1.0000\nEpoch 20/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8800\nEpoch 21/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9200\nEpoch 22/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.9200\nEpoch 23/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 1.0000\nEpoch 24/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 1.0000\nEpoch 25/200\n1/1 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9600\nEpoch 26/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 1.0000\nEpoch 27/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 1.0000\nEpoch 28/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 1.0000\nEpoch 29/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.8800\nEpoch 30/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 1.0000\nEpoch 31/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 1.0000\nEpoch 32/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 1.0000\nEpoch 33/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 1.0000\nEpoch 34/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 1.0000\nEpoch 35/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 1.0000\nEpoch 36/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 1.0000\nEpoch 37/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9600\nEpoch 38/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 1.0000\nEpoch 39/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9200\nEpoch 40/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9200\nEpoch 41/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 1.0000\nEpoch 42/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 1.0000\nEpoch 43/200\n1/1 [==============================] - 0s 56ms/step - loss: 0.0331 - accuracy: 1.0000\nEpoch 44/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9600\nEpoch 45/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9200\nEpoch 46/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 1.0000\nEpoch 47/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\nEpoch 48/200\n1/1 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000\nEpoch 49/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000\nEpoch 50/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9600\nEpoch 51/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 1.0000\nEpoch 52/200\n1/1 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000\nEpoch 53/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000\nEpoch 54/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 1.0000\nEpoch 55/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000\nEpoch 56/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000\nEpoch 57/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\nEpoch 58/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000\nEpoch 59/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9600\nEpoch 60/200\n1/1 [==============================] - 0s 59ms/step - loss: 0.0559 - accuracy: 1.0000\nEpoch 61/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000\nEpoch 62/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9600\nEpoch 63/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 1.0000\nEpoch 64/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000\nEpoch 65/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000\nEpoch 66/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000\nEpoch 67/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 1.0000\nEpoch 68/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 1.0000\nEpoch 69/200\n1/1 [==============================] - 0s 57ms/step - loss: 0.0279 - accuracy: 1.0000\nEpoch 70/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9600\nEpoch 71/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 1.0000\nEpoch 72/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 1.0000\nEpoch 73/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 1.0000\nEpoch 74/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 1.0000\nEpoch 75/200\n1/1 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 1.0000\nEpoch 76/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\nEpoch 77/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\nEpoch 78/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\nEpoch 79/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9600\nEpoch 80/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\nEpoch 81/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000\nEpoch 82/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9600\nEpoch 83/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 1.0000\nEpoch 84/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000\nEpoch 85/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\nEpoch 86/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\nEpoch 87/200\n1/1 [==============================] - 0s 58ms/step - loss: 0.0457 - accuracy: 1.0000\nEpoch 88/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 1.0000\nEpoch 89/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000\nEpoch 90/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000\nEpoch 91/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9600\nEpoch 92/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000\nEpoch 93/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\nEpoch 94/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\nEpoch 95/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\nEpoch 96/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\nEpoch 97/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\nEpoch 98/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\nEpoch 99/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9600\nEpoch 100/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000\nEpoch 101/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 102/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000\nEpoch 103/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 1.0000\nEpoch 104/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 1.0000\nEpoch 105/200\n1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 106/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9600\nEpoch 107/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9600\nEpoch 108/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\nEpoch 109/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000\nEpoch 110/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 1.0000\nEpoch 111/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000\nEpoch 112/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\nEpoch 113/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\nEpoch 114/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 1.0000\nEpoch 115/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\nEpoch 116/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\nEpoch 117/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 1.0000\nEpoch 118/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\nEpoch 119/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000\nEpoch 120/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\nEpoch 121/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\nEpoch 122/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\nEpoch 123/200\n1/1 [==============================] - 0s 55ms/step - loss: 0.0274 - accuracy: 1.0000\nEpoch 124/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9600\nEpoch 125/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000\nEpoch 126/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\nEpoch 127/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\nEpoch 128/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\nEpoch 129/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\nEpoch 130/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\nEpoch 131/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000\nEpoch 132/200\n1/1 [==============================] - 0s 58ms/step - loss: 0.0127 - accuracy: 1.0000\nEpoch 133/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\nEpoch 134/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000\nEpoch 135/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\nEpoch 136/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\nEpoch 137/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\nEpoch 138/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\nEpoch 139/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\nEpoch 140/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\nEpoch 141/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000\nEpoch 142/200\n1/1 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\nEpoch 143/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\nEpoch 144/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\nEpoch 145/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000\nEpoch 146/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9600\nEpoch 147/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\nEpoch 148/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\nEpoch 149/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 150/200\n1/1 [==============================] - 0s 62ms/step - loss: 0.0146 - accuracy: 1.0000\nEpoch 151/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\nEpoch 152/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000\nEpoch 153/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\nEpoch 154/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 1.0000\nEpoch 155/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\nEpoch 156/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 1.0000\nEpoch 157/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000\nEpoch 158/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000\nEpoch 159/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000\nEpoch 160/200\n1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 161/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9600\nEpoch 162/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\nEpoch 163/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 164/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 165/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\nEpoch 166/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\nEpoch 167/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000\nEpoch 168/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\nEpoch 169/200\n1/1 [==============================] - 0s 55ms/step - loss: 6.1011e-04 - accuracy: 1.0000\nEpoch 170/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000\nEpoch 171/200\n1/1 [==============================] - 0s 3ms/step - loss: 5.3357e-04 - accuracy: 1.0000\nEpoch 172/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000\nEpoch 173/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\nEpoch 174/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\nEpoch 175/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000\nEpoch 176/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 177/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 1.0000\nEpoch 178/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 179/200\n1/1 [==============================] - 0s 58ms/step - loss: 0.0268 - accuracy: 1.0000\nEpoch 180/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 181/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000\nEpoch 182/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\nEpoch 183/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000\nEpoch 184/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\nEpoch 185/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 186/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\nEpoch 187/200\n1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - accuracy: 1.0000\nEpoch 188/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 189/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\nEpoch 190/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\nEpoch 191/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\nEpoch 192/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\nEpoch 193/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\nEpoch 194/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000\nEpoch 195/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\nEpoch 196/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9600\nEpoch 197/200\n1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 198/200\n1/1 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\nEpoch 199/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\nEpoch 200/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\nDone\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import random\nimport json\nimport pickle\nimport numpy as np\nimport spacy\nimport codecs\nimport tensorflow as tf\n\nnlp = spacy.load('es_dep_news_trf')\n\nintentos = json.loads(codecs.open(\n    'categorias.json', 'r', encoding='utf-8').read())\n\npalabras = pickle.load(open('palabras.pkl', 'rb'))\ncategorias = pickle.load(open('categorias.pkl', 'rb'))\nmodel: tf.keras.models.Model = tf.keras.models.load_model('chatbot_model.h5')\nignorar = [\"?\", \"!\", \",\", \".\", \":\"]\n\n\ndef entradas(sentencia):\n    tokens = nlp(sentencia)\n    lemmas = set([tok.lemma_.lower()\n                  for tok in tokens if tok.text not in ignorar])\n    entrada_palabras = [0] * len(palabras)\n    for word in lemmas:\n        for i, palabra in enumerate(palabras):\n            if word == palabra:\n                entrada_palabras[i] = 1\n    return np.array(entrada_palabras)\n\n\ndef prediccion(sentencia):\n    req = entradas(sentencia)\n    res = model.predict(np.array([req]))[0]\n    error = 0.25\n    resultados = [[i, r] for i, r in enumerate(res) if r > error]\n    resultados.sort(key=lambda x: x[1], reverse=True)\n    listado = []\n    for r in resultados:\n        listado.append(\n            {'categoria': categorias[r[0]], 'probabilidad': str(r[1])})\n    print(\"prediccion-listado: \", listado)\n    return listado\n\n\ndef respuesta(sentencia):\n\n    categoria = prediccion(sentencia)[0][\"categoria\"]\n    datos = intentos[\"categorias\"]\n    res = \"No tengo muchos temas para hablar, hablemos de otra cosa\"\n    for i in datos:\n        if i[\"categoria\"] == categoria:\n            res = random.choice(i[\"respuestas\"])\n            break\n    return res\n\n\nprint(\"ChatBot Listo\")\nsalir = True\nprint(\"Chatbot, para cerrar el chat escriba 'salir'\")\nwhile salir:\n    \n    message = input(\"\")\n    print(message)\n    if message == \"salir\":\n        salir = False\n        print(\"Adios!!.\")\n    else:\n        print(respuesta(message))","metadata":{"tags":[],"cell_id":"6f1a99348a6f4de08bd5312c214bb261","source_hash":"88ed16ba","execution_start":1663553215040,"execution_millis":112779,"deepnote_app_coordinates":{"h":70,"w":12,"x":0,"y":144},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"ChatBot Listo\nChatbot, para cerrar el chat escriba 'salir'\nhola\n1/1 [==============================] - 0s 126ms/step\nprediccion-listado:  [{'categoria': 'saludos', 'probabilidad': '0.9984871'}]\nhola, en que puedo ayudarte?\ncuantos años tienes\n1/1 [==============================] - 0s 69ms/step\nprediccion-listado:  [{'categoria': 'edad', 'probabilidad': '0.9999684'}]\n6 meses es lo que tengo de creada\nque puedes \n1/1 [==============================] - 0s 70ms/step\nprediccion-listado:  [{'categoria': 'funcionamiento', 'probabilidad': '0.7002065'}, {'categoria': 'saludos', 'probabilidad': '0.2504473'}]\nsoy una ia amigable para chatear con personas\nhasta luego\n1/1 [==============================] - 0s 66ms/step\nprediccion-listado:  [{'categoria': 'despedida', 'probabilidad': '0.9933316'}]\ntenga un buen dia usted\ns\n1/1 [==============================] - 0s 16ms/step\nprediccion-listado:  [{'categoria': 'saludos', 'probabilidad': '0.67279637'}]\nhola, en que puedo ayudarte?\nsalir\nAdios!!.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=829e846e-3785-491b-bcb1-f78f25dd8f99' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_app_layout":"article","deepnote_notebook_id":"bc34c9dcd8034742b30c884c6091c283","deepnote_execution_queue":[]}}